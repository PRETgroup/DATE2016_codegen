\section{Parallel Composition}
\label{sec:composition}


\subsection{Mapping between \acp{FSM}}
\label{sec:mapping}

Given a network of \acp{FSM}, the interactions between each \ac{FSM} are 
defined as follows:
\begin{itemize}
	\item There exists a set of continuous variable inputs from all \acp{FSM} 
	globally $X_{GI}$, and a set of continuous variable outputs from all 
	\acp{FSM} globally $X_{GO}$.
	\item There exists a mapping function $\lambda(x_i) : x_o$ who takes as 
	input one of $X_{GI}$ and returns as output one of $X_{GO}$.
\end{itemize}

Such a mapping function indicates that the value of the continuous variable 
input $x_i$ should be updated with the value from the continuous variable 
output $x_o$.  Each input $x_i$ may only be mapped to at most one 
output from $X_{GO}$, however multiple inputs from $X_{GI}$ may be mapped to 
the same output $x_o$.

\begin{figure}
	\centering
	\input{figures/networkComposition}
	\caption{The parallel composition from Figure~\ref{fig:heartCellHA} 
		\label{fig:networkComposition}}
\end{figure}

For the example from Figure~\ref{fig:heartCellHA} (re-drawn in 
Figure~\ref{fig:networkComposition}), 
$X_{GI}~=~\{N_{1}.v_{I_{0}},N_{2}.v_{I_{0}}\}$ and 
$X_{GO}~=~\{N_{1}.v,N_{2}.v\}$. 
The mapping function $\lambda$ consists of 
$\lambda(N_{1}.v_{I_{0}})~:~N_{2}.v$ and $\lambda(N_{2}.v_{I_{0}})~:~N_{1}.v$.

\subsection{Synchronous Parallel}
\label{sec:synchronousParallel}

%\begin{figure}
%  \centering
%  \input{figures/cellComposition}
%  \caption{Synchronous composition of multiple heart
%    cells \label{fig:heartCellComposition}}
%\end{figure}

In order to compose the \acp{FSM} together, we take inspiration
from the synchronous language SL~\cite{SlLanguage}.  The 
concept of \emph{ticks} and \emph{reactions} are carried over, whereby each 
\ac{FSM} performs 
only a single transition (``tick'') until all other \acp{FSM} have also 
completed a transition (``reaction'') and the process can repeat.  In order to
deal with data dependencies, we also implement the delayed semantics of 
\emph{pre}
whereby the value of all inputs to each \ac{FSM} are not updated with
new values until the end of each reaction.  This allows for the behaviour of 
the system to be agnostic to the scheduling order of the individual 
\acp{FSM}.  This concept also enables us to simplify the process of 
handling cyclic \acp{ODE} (an important issue not considered in related 
work~\cite{kim2003modular}) by causing the dependencies to reference
previous, rather than current, values.

\ourTool orchestrates \acp{FSM} through the use of a round-robin
scheduler.  It executes one tick of each \ac{FSM} (the \texttt{Step} function 
described in Section~\ref{sec:backendCodeGeneration}) in series, followed by an 
\emph{I/O Synchronisation Stage} at the end of each reaction.  Such I/O 
synchronisation deals with the emission of all outputs from the system, the 
intake of all inputs to the system, and the transfer of signals between 
\acp{FSM} in the network.  This process continues indefinitely to emulate the 
dynamics of the system.  In addition, when the system initially starts up it 
enters an \emph{Initialisation Stage} whereby the \texttt{Initialization} 
function is executed.

Due to the scheduling order agnosticism described earlier, this concept is 
amenable to further scheduling algorithms that need not be sequential in 
nature.  \ourTool can be extended to support parallel computation by executing 
different \acp{FSM} on separate threads (whether logical or physical), with 
synchronisation between threads occurring at the end of each reaction.
